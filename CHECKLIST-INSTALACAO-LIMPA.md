# ‚úÖ CHECKLIST DE INSTALA√á√ÉO LIMPA - EKS DevOps Project
## Para Testes do Zero - Dezembro 2025

> üìã **Use este checklist para garantir instala√ß√£o 100% limpa e sem erros**
> 
> ‚è±Ô∏è **Tempo total estimado:** 60-90 minutos (inclui configura√ß√£o SSO do Grafana)
> 
> üí∞ **Custo do teste (2 horas):** ~$2.00 USD

---

## üì• FASE 0: PR√â-REQUISITOS (10 minutos)

### ‚úÖ Ferramentas Instaladas

- [ ] **AWS CLI v2.x** instalado
  ```bash
  aws --version
  # Esperado: aws-cli/2.x.x
  ```

- [ ] **Terraform v1.12+** instalado
  ```bash
  terraform version
  # Esperado: Terraform v1.12.x ou superior
  ```

- [ ] **kubectl compat√≠vel com EKS 1.32** instalado
  ```bash
  kubectl version --client
  # Esperado: v1.28+ (compat√≠vel com EKS 1.32)
  ```

- [ ] **Helm v3.x** instalado
  ```bash
  helm version
  # Esperado: v3.x
  ```

- [ ] **jq** instalado (para valida√ß√µes)
  ```bash
  jq --version
  ```

### ‚úÖ Conta AWS Configurada

- [ ] **Conta AWS Paid Plan** ou cr√©ditos suficientes
  > ‚ö†Ô∏è **CR√çTICO:** Free Tier N√ÉO suporta inst√¢ncias t3.medium

- [ ] **Permiss√µes administrativas** na conta
  ```bash
  aws iam get-user
  # Deve retornar seu usu√°rio sem erro
  ```

- [ ] **Regi√£o confirmada:** `us-east-1` (Virg√≠nia do Norte)
  ```bash
  aws configure get region
  # Deve retornar: us-east-1
  ```

---

## üîê FASE 1: CONFIGURA√á√ÉO DE CREDENCIAIS (15 minutos)

### Passo 1.1: Criar Usu√°rio IAM

```bash
# Substitua <SEU_USUARIO> por ex: terraform-deploy
aws iam create-user --user-name <SEU_USUARIO>
```

- [ ] Usu√°rio criado com sucesso
- [ ] Anote o nome do usu√°rio: `_______________`

### Passo 1.2: Criar Terraform Role

```bash
# Obter Account ID
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
echo "Seu Account ID: $ACCOUNT_ID"

# Criar Role (substitua <SEU_USUARIO>)
aws iam create-role \
    --role-name terraform-role \
    --assume-role-policy-document '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::'$ACCOUNT_ID':user/<SEU_USUARIO>"
            },
            "Action": "sts:AssumeRole",
            "Condition": {
                "StringEquals": {
                    "sts:ExternalId": "3b94ec31-9d0d-4b22-9bce-72b6ab95fe1a"
                }
            }
        }]
    }'
```

- [ ] Role criada com sucesso
- [ ] Account ID anotado: `_______________`

### Passo 1.3: Anexar Permiss√µes Administrativas

```bash
aws iam attach-role-policy \
    --role-name terraform-role \
    --policy-arn arn:aws:iam::aws:policy/AdministratorAccess
```

- [ ] Policy anexada com sucesso

### Passo 1.4: Configurar AWS CLI Profile

Edite `~/.aws/config` e adicione:

```ini
[profile terraform]
role_arn = arn:aws:iam::<SEU_ACCOUNT_ID>:role/terraform-role
source_profile = default
external_id = 3b94ec31-9d0d-4b22-9bce-72b6ab95fe1a
region = us-east-1
```

**Substitui√ß√µes necess√°rias:**
- [ ] `<SEU_ACCOUNT_ID>` ‚Üí Account ID real
- [ ] `source_profile = default` ‚Üí perfil que tem credenciais do usu√°rio IAM

### Passo 1.5: Testar Assume Role

```bash
aws sts get-caller-identity --profile terraform
```

**Resultado esperado:**
```json
{
    "UserId": "AROAXXXXXXXXX:botocore-session-xxxxx",
    "Account": "123456789012",
    "Arn": "arn:aws:sts::123456789012:assumed-role/terraform-role/..."
}
```

- [ ] Profile terraform funcionando ‚úÖ
- [ ] AssumedRoleUser cont√©m "terraform-role" ‚úÖ

---

## üìÇ FASE 2: CLONAR E CONFIGURAR PROJETO (5 minutos)

### Passo 2.1: Clonar Reposit√≥rio

```bash
git clone https://github.com/jlui70/lab-eks-terraform-ansible.git
cd lab-eks-terraform-ansible
```

- [ ] Reposit√≥rio clonado com sucesso

### Passo 2.2: Substituir Account ID

```bash
# Obter Account ID (se ainda n√£o tiver)
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text --profile terraform)
echo "Account ID: $ACCOUNT_ID"

# Substituir <YOUR_ACCOUNT> em TODOS os arquivos .tf
find . -name "*.tf" -type f -exec sed -i "s/<YOUR_ACCOUNT>/$ACCOUNT_ID/g" {} +

# VALIDAR substitui√ß√£o
grep -r "<YOUR_ACCOUNT>" --include="*.tf" .
```

**Resultado esperado:** `(sem output = todas substitui√ß√µes OK)`

- [ ] Nenhum `<YOUR_ACCOUNT>` restante nos arquivos `.tf` ‚úÖ

### Passo 2.3: Validar Substitui√ß√µes

```bash
# Verificar 3 arquivos cr√≠ticos
grep "eks-devopsproject-state-files" 00-backend/variables.tf
# Deve mostrar: eks-devopsproject-state-files-123456789012

grep "role/terraform-role" 01-networking/variables.tf
# Deve mostrar: arn:aws:iam::123456789012:role/terraform-role

grep "bucket" 02-eks-cluster/main.tf | head -1
# Deve mostrar: bucket com seu Account ID
```

- [ ] Todos os 3 arquivos mostram Account ID real ‚úÖ

---

## üèóÔ∏è FASE 3: DEPLOYMENT DA INFRAESTRUTURA (60 minutos)

### ‚ö° OP√á√ÉO A: Deploy Autom√°tico (Recomendado)

```bash
# Script que aplica TODAS as 6 stacks automaticamente
./rebuild-all.sh
```

**O script vai:**
1. ‚úÖ Stack 00 ‚Üí Backend S3 + DynamoDB
2. ‚úÖ Stack 01 ‚Üí VPC com subnets /26 (59 IPs cada)
3. ‚úÖ Stack 02 ‚Üí EKS Cluster + VPC CNI otimizado
4. ‚úÖ Stack 03 ‚Üí Karpenter auto-scaling
5. ‚úÖ Stack 04 ‚Üí WAF (se tiver apps)
6. ‚úÖ Stack 05 ‚Üí Grafana + Prometheus + API Key

- [ ] rebuild-all.sh executado sem erros ‚úÖ
- [ ] Aguardar ~60 minutos ‚è±Ô∏è

**Pular para Fase 4 (Valida√ß√µes)**

---

### üîß OP√á√ÉO B: Deploy Manual (Passo a Passo)

#### Stack 00 - Backend (1 min)

```bash
cd 00-backend
terraform init
terraform apply -auto-approve
cd ..
```

- [ ] 3 recursos criados: S3 bucket + versioning + DynamoDB table ‚úÖ

#### Stack 01 - Networking (3 min)

```bash
cd 01-networking
terraform init
terraform apply -auto-approve
cd ..
```

**VALIDAR subnets expandidas:**
```bash
terraform output -json | jq '.private_subnet_cidr_blocks.value'
# Deve mostrar: ["10.0.1.0/26", "10.0.1.64/26"]
```

- [ ] 21 recursos criados ‚úÖ
- [ ] Subnets privadas s√£o /26 (59 IPs cada) ‚úÖ

#### Stack 02 - EKS Cluster (20 min)

```bash
cd 02-eks-cluster
terraform init
terraform apply -auto-approve
```

**VALIDAR VPC CNI otimizado:**
```bash
terraform state show aws_eks_addon.vpc_cni | grep WARM
# Deve mostrar:
# WARM_ENI_TARGET = 0
# WARM_IP_TARGET = 5
# MINIMUM_IP_TARGET = 10
```

- [ ] 21 recursos criados ‚úÖ
- [ ] VPC CNI addon configurado com otimiza√ß√£o ‚úÖ

**Configurar kubectl:**
```bash
aws eks update-kubeconfig \
    --name eks-devopsproject-cluster \
    --region us-east-1 \
    --profile terraform

# Testar acesso
kubectl get nodes
```

- [ ] kubectl configurado ‚úÖ
- [ ] 3 nodes em status `Ready` ‚úÖ

#### Stack 03 - Karpenter (5 min)

```bash
cd ../03-karpenter-auto-scaling
terraform init
terraform apply -auto-approve
cd ..
```

**VALIDAR Karpenter:**
```bash
kubectl get pods -n kube-system | grep karpenter
# Esperado: 2 pods Running

kubectl get nodepools
# Esperado: default pool com status Ready
```

- [ ] 10 recursos criados ‚úÖ
- [ ] Karpenter controller rodando ‚úÖ
- [ ] NodePool default criado ‚úÖ

#### Stack 04 - Security (1 min) - OPCIONAL

```bash
cd ../04-security
terraform init
terraform apply -auto-approve
cd ..
```

> ‚ö†Ô∏è **NOTA:** WAF s√≥ funciona se voc√™ j√° tiver ALB criado por Ingress.
> Se n√£o tiver app ainda, pule para Stack 05.

- [ ] WAF Web ACL criado ‚úÖ (ou pulado)

#### Stack 05 - Monitoring (25 min)

```bash
cd ../05-monitoring
terraform init
terraform apply -auto-approve
```

**VALIDAR Prometheus Scraper:**
```bash
terraform state show aws_prometheus_scraper.this | grep lifecycle
# Deve mostrar: create_before_destroy = false
```

**Obter outputs:**
```bash
terraform output
# Anote:
# - grafana_workspace_url
# - grafana_workspace_id
# - grafana_api_key (ser√° usado no Ansible)
```

- [ ] 7 recursos criados ‚úÖ
- [ ] Prometheus scraper com lifecycle hook ‚úÖ
- [ ] Grafana API Key criada ‚úÖ
- [ ] Outputs anotados ‚úÖ

---

## ‚úÖ FASE 4: VALIDA√á√ïES DA INFRAESTRUTURA (10 minutos)

### Valida√ß√£o 4.1: Cluster EKS

```bash
# Nodes
kubectl get nodes
# Esperado: 3 nodes Ready

# Pods do sistema
kubectl get pods -A
# Esperado: Todos Running (coredns, aws-node, kube-proxy, etc)

# Addons EKS
aws eks list-addons --cluster-name eks-devopsproject-cluster --profile terraform
# Esperado: vpc-cni, coredns, kube-proxy, aws-ebs-csi-driver, eks-pod-identity-agent
```

- [ ] 3 nodes Ready ‚úÖ
- [ ] Todos os pods Running ‚úÖ
- [ ] 5+ addons instalados ‚úÖ

### Valida√ß√£o 4.2: VPC CNI Otimizado

```bash
# Verificar configura√ß√£o do CNI
kubectl set env daemonset aws-node -n kube-system --list | grep WARM
# Esperado:
# WARM_ENI_TARGET=0
# WARM_IP_TARGET=5
# MINIMUM_IP_TARGET=10
```

- [ ] VPC CNI com otimiza√ß√£o aplicada ‚úÖ

### Valida√ß√£o 4.3: Karpenter

```bash
# NodePools
kubectl get nodepools
# Esperado: default (Ready)

# EC2NodeClasses
kubectl get ec2nodeclasses
# Esperado: default (Ready)

# Karpenter logs
kubectl logs -n kube-system -l app.kubernetes.io/name=karpenter --tail=20
# Esperado: Sem erros cr√≠ticos
```

- [ ] NodePool e EC2NodeClass prontos ‚úÖ
- [ ] Karpenter sem erros nos logs ‚úÖ

### Valida√ß√£o 4.4: ALB Controller

```bash
# Pods do ALB Controller
kubectl get pods -n kube-system | grep aws-load-balancer
# Esperado: 2 pods Running

# Logs (√∫ltimas 10 linhas)
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=10
```

- [ ] ALB Controller rodando ‚úÖ

### Valida√ß√£o 4.5: Prometheus + Grafana

```bash
# Verificar scraper
aws amp list-scrapers --profile terraform
# Esperado: 1 scraper ativo

# Verificar workspace Grafana
aws grafana list-workspaces --profile terraform
# Esperado: 1 workspace
```

- [ ] Prometheus scraper ativo ‚úÖ
- [ ] Grafana workspace criado ‚úÖ

### Valida√ß√£o 4.6: Subnets com IPs Suficientes

```bash
# Verificar IPs dispon√≠veis
aws ec2 describe-subnets \
    --filters "Name=tag:Name,Values=private-subnet-us-east-1a" \
    --query 'Subnets[0].AvailableIpAddressCount' \
    --output text \
    --profile terraform
# Esperado: ~50-55 IPs dispon√≠veis (de 59 total)
```

- [ ] Subnet /26 com 50+ IPs dispon√≠veis ‚úÖ

---

## üé® FASE 5: CONFIGURAR GRAFANA SSO (10 minutos)

> ‚ö†Ô∏è **OBRIGAT√ìRIO:** Sem isso, Grafana fica inacess√≠vel

### Passo 5.1: Habilitar IAM Identity Center (SSO)

1. Acesse: AWS Console ‚Üí IAM Identity Center
2. Clique "Enable"
3. Escolha regi√£o: **us-east-1**
4. Aguarde ~2 min

- [ ] IAM Identity Center habilitado ‚úÖ

### Passo 5.2: Criar Usu√°rio SSO

1. IAM Identity Center ‚Üí Users ‚Üí Add user
2. Preencha:
   - Username: `grafana-admin`
   - Email: seu email real
   - First/Last name: seu nome
3. Enviar convite por email

- [ ] Usu√°rio SSO criado ‚úÖ
- [ ] Email de convite recebido ‚úÖ

### Passo 5.3: Atribuir Usu√°rio ao Grafana

1. AWS Console ‚Üí Amazon Managed Grafana
2. Clique no workspace criado
3. Aba "Authentication" ‚Üí Assign new user or group
4. Selecione `grafana-admin`
5. **CR√çTICO:** Role = `Admin` (n√£o Viewer ou Editor!)

- [ ] Usu√°rio atribu√≠do ao workspace ‚úÖ
- [ ] Role = **Admin** ‚úÖ

### Passo 5.4: Acessar Grafana

1. AWS Access Portal ‚Üí Applications ‚Üí Grafana workspace
2. OU copie URL do `terraform output grafana_workspace_url`
3. Login com usu√°rio SSO

- [ ] Grafana acess√≠vel ‚úÖ
- [ ] Login bem-sucedido ‚úÖ

---

## ü§ñ FASE 6: CONFIGURAR GRAFANA COM ANSIBLE (2 minutos)

> üí° **Alternativa r√°pida:** Ao inv√©s de configurar Grafana manualmente

### Passo 6.1: Instalar Ansible (se n√£o tiver)

```bash
# Ubuntu/Debian
sudo apt install ansible -y

# macOS
brew install ansible

# Verificar
ansible --version
```

- [ ] Ansible instalado ‚úÖ

### Passo 6.2: Executar Playbook de Configura√ß√£o

```bash
# Obter API Key do Terraform
cd 05-monitoring
GRAFANA_API_KEY=$(terraform output -raw grafana_api_key)
cd ..

# Configurar Grafana (data source + dashboard)
cd ansible
ansible-playbook playbooks/01-configure-grafana.yml \
    -e "grafana_api_key=$GRAFANA_API_KEY"
cd ..
```

**O playbook configura automaticamente:**
1. ‚úÖ Data Source Prometheus
2. ‚úÖ Dashboard Node Exporter (ID 1860)
3. ‚úÖ Valida conectividade

- [ ] Playbook executado sem erros ‚úÖ
- [ ] Data Source Prometheus aparece no Grafana ‚úÖ
- [ ] Dashboard "Node Exporter Full" importado ‚úÖ

### Passo 6.3: Validar no Grafana

1. Acesse Grafana ‚Üí Configuration ‚Üí Data Sources
2. Deve ter: **Amazon Managed Service for Prometheus**
3. Acesse Dashboards ‚Üí Procure "Node Exporter Full"
4. Dashboard deve mostrar m√©tricas dos nodes

- [ ] Data Source configurado ‚úÖ
- [ ] Dashboard com dados reais ‚úÖ

---

## üéØ FASE 7: DEPLOY APP DE TESTE (OPCIONAL - 3 minutos)

### Op√ß√£o A: E-commerce App com Ansible

```bash
cd ansible
ansible-playbook playbooks/03-deploy-ecommerce.yml
ansible-playbook playbooks/04-configure-ecommerce-monitoring.yml
cd ..
```

**Resultado:**
- 7 microservi√ßos deployados
- Ingress + ALB criado
- Monitoramento configurado

- [ ] App deployado ‚úÖ
- [ ] ALB acess√≠vel via browser ‚úÖ

### Op√ß√£o B: NGINX Simples

```bash
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-test
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-test
spec:
  type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: nginx
EOF

# Obter URL
kubectl get svc nginx-test
```

- [ ] NGINX deployado ‚úÖ
- [ ] Service criado ‚úÖ

---

## üóëÔ∏è FASE 8: DESTROY (15-25 minutos)

### Pr√©-valida√ß√£o (Opcional)

```bash
./pre-destroy-check.sh
```

- [ ] Script executado ‚úÖ
- [ ] Warnings revisados ‚úÖ

### Destroy Autom√°tico

```bash
./destroy-all.sh
```

**O script vai:**
1. ‚úÖ Deletar recursos Kubernetes (namespaces, ALBs)
2. ‚úÖ Aguardar 45s para ALBs serem removidos
3. ‚úÖ Destroy Stack 05 (Prometheus + Grafana)
4. ‚úÖ **Aguardar automaticamente** at√© 10min para ENIs serem liberadas
5. ‚úÖ Destroy Stacks 04 ‚Üí 03 ‚Üí 02 ‚Üí 01
6. ‚úÖ Perguntar se quer destruir Stack 00 (backend)

- [ ] destroy-all.sh executado ‚úÖ
- [ ] Todos os recursos deletados ‚úÖ

### Se VPC n√£o deletar (raro)

```bash
# Aguardar 5-10min e executar
./cleanup-vpc-final.sh
```

- [ ] VPC deletada ‚úÖ

### Validar Custo Zero

```bash
# Verificar recursos restantes
aws eks list-clusters --profile terraform
# Esperado: []

aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --profile terraform
# Esperado: []

aws elbv2 describe-load-balancers --profile terraform
# Esperado: []
```

- [ ] Nenhum cluster EKS ‚úÖ
- [ ] Nenhuma inst√¢ncia EC2 ‚úÖ
- [ ] Nenhum ALB ‚úÖ
- [ ] Custo estimado: **$0/m√™s** ‚úÖ

---

## üìä RESUMO DO CHECKLIST

### ‚úÖ Tudo OK para Produ√ß√£o?

- [ ] **Credenciais:** terraform-role configurada e testada
- [ ] **C√≥digo:** Nenhum `<YOUR_ACCOUNT>` restante
- [ ] **Networking:** Subnets /26 com 50+ IPs dispon√≠veis
- [ ] **EKS:** VPC CNI otimizado (WARM_ENI_TARGET=0)
- [ ] **Karpenter:** NodePools e EC2NodeClasses prontos
- [ ] **Monitoring:** Prometheus scraper com lifecycle hooks
- [ ] **Grafana:** SSO configurado + Data Source + Dashboard
- [ ] **Scripts:** rebuild-all.sh e destroy-all.sh testados
- [ ] **Destroy:** VPC deletada sem problemas de ENI

### üéâ RESULTADO ESPERADO

Se todos os checkboxes est√£o marcados:

‚úÖ **Instala√ß√£o 100% limpa e funcional**
‚úÖ **Sem problemas de IPs (subnets /26)**
‚úÖ **Sem problemas de destroy (ENIs do Prometheus)**
‚úÖ **Grafana funcionando com SSO + Dashboards**
‚úÖ **Pronto para demonstra√ß√µes e testes**

---

## üö® PROBLEMAS COMUNS E SOLU√á√ïES

### Problema 1: "the server has asked for the client to provide credentials"

**Causa:** Access entry da terraform-role n√£o configurado

**Solu√ß√£o:**
```bash
cd 02-eks-cluster
terraform apply -auto-approve
aws eks update-kubeconfig --name eks-devopsproject-cluster --region us-east-1 --profile terraform
```

### Problema 2: "InsufficientFreeAddresses"

**Causa:** Subnets ainda /27 (c√≥digo antigo)

**Valida√ß√£o:**
```bash
cd 01-networking
grep "cidr_block.*10.0.1" variables.tf
# Deve mostrar: 10.0.1.0/26 e 10.0.1.64/26
```

**Solu√ß√£o:** C√≥digo j√° corrigido, apenas execute terraform apply

### Problema 3: VPC n√£o deleta (ENIs bloqueando)

**Causa:** ENIs do Prometheus scraper n√£o foram liberadas

**Solu√ß√£o:** C√≥digo j√° corrigido com prote√ß√£o autom√°tica no destroy-all.sh
- Script aguarda at√© 10min automaticamente
- Se ainda falhar: `./cleanup-vpc-final.sh`

### Problema 4: Grafana retorna 403 Forbidden (Ansible)

**Causa:** Usu√°rio SSO n√£o √© Admin

**Solu√ß√£o:**
1. AWS Console ‚Üí Amazon Managed Grafana
2. Workspace ‚Üí Authentication ‚Üí Editar usu√°rio
3. **Mudar Role para Admin**
4. Reexecutar playbook Ansible

---

## üìû SUPORTE

Se encontrar problemas:

1. ‚úÖ Revisar se√ß√£o **Troubleshooting** no README.md (Erros 1-9)
2. ‚úÖ Executar `./pre-destroy-check.sh` para diagn√≥stico
3. ‚úÖ Verificar logs: `kubectl logs -n kube-system <pod>`
4. ‚úÖ Consultar documenta√ß√£o Ansible em `docs/`

**Boa sorte com os testes! üöÄ**
